{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What are the most common reasons for missing data in ETL pipelines?\n",
        "\n",
        "- Answer 1\n",
        "\n",
        "Data Entry Errors: Human error where a field is skipped or typed incorrectly.\n",
        "\n",
        "System Integration Issues: Data being pulled from legacy systems that donâ€™t share the same schema or mandatory fields.\n",
        "\n",
        "Network/Sensor Failures: In IoT or real-time streaming, a temporary \"dropout\" in connection can lead to lost packets of data.\n",
        "\n",
        "Optional Fields: Users simply choosing not to provide information.\n",
        "\n",
        "\n",
        "Q2. Why is blindly deleting rows with missing values considered a bad practice in ETL?\n",
        "\n",
        "- Answer 2\n",
        "\n",
        "Loss of Information: You throw away valuable data in the non-missing columns of that row.\n",
        "\n",
        "Introduction of Bias: If the data isn't missing completely at random, deleting rows can skew your results. For example, if low-income earners are less likely to report their salary, deleting those rows will artificially inflate the average income of your dataset.\n",
        "\n",
        "Q3. Explain the difference between:\n",
        "\n",
        "Listwise deletion\n",
        "\n",
        "Column deletion\n",
        "\n",
        "Also mention one scenario where each is appropriate.\n",
        "\n",
        "- Answer 3\n",
        "\n",
        "- Listwise Deletion,\n",
        "\n",
        "Removing the entire row if any single value is missing.,\n",
        "\n",
        "When the dataset is massive and the missingness is truly random.\n",
        "\n",
        "- Column Deletion,\n",
        "\n",
        "Removing an entire feature/column from the dataset.,\n",
        "\n",
        "\"When a column has so many missing values that it provides no predictive power.\"\n",
        "\n",
        "Q4. Why is median imputation preferred over mean imputation for skewed data such as income?\n",
        "\n",
        "- Answer 4\n",
        "\n",
        "The mean is highly sensitive to outliers. In a dataset like income, a few billionaires can drag the mean significantly higher than what a \"typical\" person earns. The median is the middle value and remains robust against these extremes, providing a more realistic \"typical\" value to fill in the gaps.\n",
        "\n",
        "Q5. What is forward fill and in what type of dataset is it most useful?\n",
        "\n",
        "- Answer 5\n",
        "\n",
        "Forward fill (ffill) carries the last known non-null value forward to replace the subsequent missing value.\n",
        "\n",
        "Use Case: It is most useful in Time-Series data. For example, if a stock price is recorded every minute but the value for 10:01 AM is missing, it is logical to assume it is the same as the 10:00 AM price until a new change is recorded.\n",
        "\n",
        "Q6. Why should flagging missing values be done before imputation in an ETL workflow?\n",
        "\n",
        "- Answer 6\n",
        "\n",
        "Flagging involves creating a new binary column (e.g., is_income_missing) before you fill the hole with a mean or median.\n",
        "\n",
        "It preserves the information that a value was originally missing. This allows downstream models to \"learn\" if the absence of data itself is a pattern, and it prevents the imputed values from being indistinguishable from actual observed values.\n",
        "\n",
        "Q7. Consider a scenario where income is missing for many customers.\n",
        " How can this missingness itself provide business insights?\n",
        "\n",
        "- Answer 7\n",
        "\n",
        "    Missingness is often informative. In the case of income:\n",
        "\n",
        "    Behavioral Insight: It might indicate a lack of trust in the brand.\n",
        "\n",
        "    Demographic Insight: It could suggest that the customers are in a specific age bracket who don't have a \"standard\" monthly salary and therefore leave it blank.\n",
        "\n",
        "    UX Insight: It could mean the input field on your app is broken or confusing for certain device types.\n",
        "\n",
        "\n",
        "Q8. Listwise Deletion\n",
        "\n",
        "Remove all rows where Region is missing.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Identify affected rows\n",
        "\n",
        "Show the dataset after deletion\n",
        "\n",
        "Mention how many records were lost\n",
        "\n",
        "- Answer\n",
        "\n",
        "1. Identify Affected Rows\n",
        "\n",
        "    Affected Row: Customer_ID 105 (Amit Verma)\n",
        "    \n",
        "2. Dataset After Deletion\n",
        "\n",
        "\n",
        "3. Records LostTotal records lost: 1 record (Customer 105).\n",
        "\n",
        "Q9. Imputation\n",
        "\n",
        "Handle missing values in Monthly_Sales using:\n",
        "\n",
        "Forward Fill\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Apply forward fill\n",
        "\n",
        "Show before vs after values\n",
        "\n",
        "Explain why forward fill is suitable here\n",
        "\n",
        "- Answer 9\n",
        "\n",
        "1. Apply Forward Fill  \n",
        "We will focus on the Monthly_Sales column. The missing values (NaN) at IDs 102, 104, and 106 will take the value of the record immediately preceding them.\n",
        "\n",
        "2. Before vs After Values\n",
        "\n",
        "3. Why Forward Fill is suitable here\n",
        "\n",
        "Forward fill is often used in time-series or ordered data. In a business context, if sales data is reported sequentially, it assumes that the current period's performance is similar to the previous one, maintaining the continuity of the dataset without reducing the sample size like deletion would.\n",
        "\n",
        "\n",
        "Q10. Flagging Missing Data\n",
        "\n",
        "Create a flag column for missing Income.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "Create Income_Missing_Flag (0 = present, 1 = missing)\n",
        "\n",
        "Show updated dataset\n",
        "\n",
        "Count how many customers have missing income\n",
        "\n",
        "- Answer 10\n",
        "\n",
        "1. & 2. Show Updated Dataset (with Flag Column)\n",
        "We create Income_Missing_Flag where 0 = present and 1 = missing.\n",
        "\n",
        "3. Count of customers with missing income\n",
        "By summing the flag column, we can see:\n",
        "\n",
        "Total customers with missing income: 3 (Anjali Rao, Neha Singh, and Pooja Das).\n"
      ],
      "metadata": {
        "id": "_3bnws8h0_kw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM0SpDAl09ar"
      },
      "outputs": [],
      "source": []
    }
  ]
}